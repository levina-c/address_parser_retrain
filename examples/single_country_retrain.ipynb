{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCCTVsZcoIxE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "from deepparse.dataset_container import PickleDatasetContainer\n",
        "from deepparse.parser import AddressParser\n",
        "import shutil\n",
        "from poutyne import set_seeds\n",
        "import poutyne\n",
        "import timeit\n",
        "import uk_test_data\n",
        "import training\n",
        "from pathlib import Path\n",
        "\n",
        "seed = 42\n",
        "set_seeds(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMywHl1IoIxG"
      },
      "outputs": [],
      "source": [
        "# Retrain an Address Parser for Single Country Uses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbxiEdeDoIxG"
      },
      "source": [
        "In this project, a pre-trained model is retrained to maximize its performance for UK addresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBJ_nU1soIxH"
      },
      "source": [
        "## Retrain a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yavI89e0oIxH"
      },
      "source": [
        "First, to retrain the supervised model, we need parsed address example, the sample data set is from Companies House."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_3adCWZoIxJ"
      },
      "outputs": [],
      "source": [
        "root_dir = os.path.join(\"../data/\")\n",
        "pkl_file_extension = \".p\"\n",
        "training_dataset_name = \"uk_training_data\"\n",
        "test_dataset_name = \"uk_test_data\"\n",
        "checkpoints_dir = \"./checkpoints/uk\"\n",
        "tag_dictionary = {\"CareOf\": 0, \"Unit\": 1, \"Floor\": 2, \"Building\": 3, \"StreetNumber\": 4, \"StreetName\": 5, \"District\": 6, \"City\": 7, \"Village\": 8, \"Estate\": 9, \"Town\": 10, \"POBox\": 11, \"PostCode\": 12, \"EOS\": 13}\n",
        "\n",
        "test_pkl_path = os.path.join(root_dir, \"pkl\", test_dataset_name + pkl_file_extension)\n",
        "training_pkl_path =  os.path.join(root_dir, \"pkl\", training_dataset_name + pkl_file_extension)\n",
        "\n",
        "# create pickle dataset\n",
        "with open(test_pkl_path, 'wb') as f:\n",
        "    pickle.dump(uk_test_data.test, f)\n",
        "\n",
        "with open(training_pkl_path, 'wb') as f:\n",
        "    pickle.dump(training.training, f)\n",
        "\n",
        "read = pickle.load(open(training_pkl_path, 'rb'))\n",
        "print(read)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZbPBkzMoIxJ"
      },
      "source": [
        "Now, let's import our train and test datasets into memory to retrain our parser model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58E5pLCZoIxJ"
      },
      "outputs": [],
      "source": [
        "training_container = PickleDatasetContainer(training_pkl_path)\n",
        "test_container = PickleDatasetContainer(test_pkl_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZhxV1aGoIxJ"
      },
      "source": [
        "We will use the FastText one for our base pre-trained model since it is faster to retrain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43UXW2wfoIxK",
        "outputId": "e16b9f94-f10b-4336-9285-4e1d28921ee4"
      },
      "outputs": [],
      "source": [
        "address_parser = AddressParser(model_type=\"fasttext\", device=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVRA0di8oIxK"
      },
      "source": [
        "But first, let's see what the performance is before retraining."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1VubJDsoIxL"
      },
      "outputs": [],
      "source": [
        "address_parser.test(test_container, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5sHeslVoIxL",
        "outputId": "5b6dcc77-3922-4492-e40b-aa2fec732369",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "_ = address_parser.retrain(\n",
        "    training_container,\n",
        "    train_ratio=0.8,\n",
        "    epochs=5,\n",
        "    batch_size=8,\n",
        "    num_workers=3,\n",
        "    learning_rate=0.001,\n",
        "    prediction_tags=tag_dictionary,\n",
        "    logging_path=checkpoints_dir,\n",
        "    name_of_the_retrain_parser=\"UKParser\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ28p1EGoIxL",
        "outputId": "7ca93894-fa7c-4a72-c912-7a7c5b6ca634"
      },
      "outputs": [],
      "source": [
        "address_parser.test(test_container, batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqNKwtA9oIxM"
      },
      "source": [
        "To further improve performance, we could train for longer, increase the training dataset size (the actual size of 100,000 addresses), or rework the Seq2Seq hidden sizes. See the [retrain interface documentation](https://deepparse.org/parser.html#deepparse.parser.AddressParser.retrain) for all the training parameters."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
